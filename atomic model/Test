import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import matplotlib.gridspec as gridspec
from matplotlib.patches import Patch
import os
import io
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor
from pptx.enum.shapes import MSO_SHAPE
from pptx.enum.text import PP_ALIGN

def read_data(query_file, condition_file):
    """
    读取查询数据和条件数据
    处理列名差异（Wafer ID vs WaferID）
    """
    try:
        query_data = pd.read_excel(query_file)
        condition_data = pd.read_excel(condition_file)
        
        print(f"成功读取 {query_file} 和 {condition_file}")
        print(f"IEDA2_query.xlsx 形状: {query_data.shape}")
        print(f"condition_list.xlsx 形状: {condition_data.shape}")
        
        # 检查列名
        print("\nIEDA2_query.xlsx 列名:", query_data.columns.tolist())
        print("condition_list.xlsx 列名:", condition_data.columns.tolist())
        
        return query_data, condition_data
    except Exception as e:
        print(f"读取文件时出错: {e}")
        return None, None

def transform_data(query_data, condition_data):
    """
    将查询数据和条件数据转换为所需的格式
    处理列名差异（Wafer ID vs WaferID）
    处理Condition列包含BSL和2nd tool信息
    """
    # 查找查询数据中的Wafer ID列
    wafer_id_query = "Wafer ID" if "Wafer ID" in query_data.columns else "WaferID"
    if wafer_id_query not in query_data.columns:
        # 寻找可能包含wafer id的列
        for col in query_data.columns:
            if "wafer" in col.lower():
                wafer_id_query = col
                break
    
    # 查找条件数据中的WaferID列
    wafer_id_condition = "WaferID" if "WaferID" in condition_data.columns else "Wafer ID"
    if wafer_id_condition not in condition_data.columns:
        # 寻找可能包含wafer id的列
        for col in condition_data.columns:
            if "wafer" in col.lower():
                wafer_id_condition = col
                break
    
    # 查找参数名列和值列
    parameter_col = None
    value_col = None
    for col in query_data.columns:
        if "Parameter Name" in col or "name" in col.lower():
            parameter_col = col
        elif "value" in col.lower() or "site value" in col.lower():
            value_col = col
    
    # 查找条件列
    condition_col = None
    for col in condition_data.columns:
        if "condition" in col.lower():
            condition_col = col
            break
    
    print(f"\n使用以下列名进行数据处理:")
    print(f"查询数据Wafer ID列: {wafer_id_query}")
    print(f"条件数据WaferID列: {wafer_id_condition}")
    print(f"参数名列: {parameter_col}")
    print(f"值列: {value_col}")
    print(f"条件列: {condition_col}")
    
    # 获取条件类型（通常是Baseline和2nd tool）
    if condition_col and condition_col in condition_data.columns:
        condition_types = condition_data[condition_col].unique()
        print(f"发现的条件类型: {condition_types}")
    else:
        condition_types = ["Baseline", "2nd tool"]
        print(f"使用默认条件类型: {condition_types}")
    
    # 获取参数列表 - 从query_data的parameter_col列中提取唯一值
    if parameter_col and parameter_col in query_data.columns:
        measure_parameters = query_data[parameter_col].unique()
        print(f"发现的电性量测项目: {measure_parameters}")
    else:
        measure_parameters = ["Con_M3LA", "Con_M3LB", "Rc_V2v", "LK_M3LA", "LK_M3LB"]
        print(f"使用默认电性量测项目: {measure_parameters}")
    
    # 合并数据
    print("\n合并数据...")
    merged_data = pd.merge(
        query_data, 
        condition_data, 
        left_on=wafer_id_query, 
        right_on=wafer_id_condition, 
        how='left'
    )
    
    # 创建数据透视表
    try:
        print("创建数据透视表...")
        # 先按Wafer ID和Parameter Name取平均，再创建透视表
        grouped_data = merged_data.groupby([wafer_id_query, parameter_col, condition_col])[value_col].mean().reset_index()
        
        pivot_data = grouped_data.pivot_table(
            index=[wafer_id_query, condition_col],
            columns=parameter_col,
            values=value_col
        ).reset_index()
        
        print(f"数据透视表形状: {pivot_data.shape}")
        
        return pivot_data, condition_types, measure_parameters, wafer_id_query, condition_col
    
    except Exception as e:
        print(f"创建数据透视表时出错: {e}")
        
        # 备用方法
        print("使用备用方法...")
        
        # 获取唯一的参数
        unique_params = merged_data[parameter_col].unique()
        print(f"找到 {len(unique_params)} 个唯一参数")
        
        # 创建新的数据框
        transformed_data = merged_data[[wafer_id_query, condition_col]].drop_duplicates()
        
        # 为每个参数创建列
        for param in unique_params:
            param_data = merged_data[merged_data[parameter_col] == param]
            param_data_grouped = param_data.groupby(wafer_id_query)[value_col].mean().reset_index()
            param_data_grouped = param_data_grouped.rename(columns={value_col: param})
            
            # 合并到转换后的数据
            transformed_data = pd.merge(transformed_data, param_data_grouped, on=wafer_id_query, how='left')
        
        print(f"备用转换数据形状: {transformed_data.shape}")
        
        return transformed_data, condition_types, measure_parameters, wafer_id_query, condition_col

def remove_outliers(data, parameter, group_col, group_values, method='iqr', k=1.5):
    """
    移除异常值但不修改原始数据
    method: 'iqr' 使用四分位距法, 'zscore' 使用Z-score法
    k: IQR方法的倍数或Z-score方法的阈值
    返回移除异常值后的数据副本
    """
    # 创建数据副本，避免修改原始数据
    clean_data = data.copy()
    
    # 对每个组应用异常值检测
    for group in group_values:
        # 获取组内参数数据
        mask = data[group_col] == group
        group_data = data.loc[mask, parameter]
        
        if len(group_data) <= 3:  # 样本太少，不做异常值检测
            continue
        
        if method == 'iqr':
            # IQR方法
            Q1 = group_data.quantile(0.25)
            Q3 = group_data.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - k * IQR
            upper_bound = Q3 + k * IQR
            
            # 标记组内异常值
            outlier_mask = (group_data < lower_bound) | (group_data > upper_bound)
            
        elif method == 'zscore':
            # Z-score方法
            z_scores = np.abs(stats.zscore(group_data))
            outlier_mask = z_scores > k
            
        else:
            raise ValueError(f"不支持的异常值检测方法: {method}")
        
        # 在副本中设置异常值为NaN
        if outlier_mask.any():
            outlier_indices = group_data[outlier_mask].index
            clean_data.loc[outlier_indices, parameter] = np.nan
            
            # 打印异常值信息
            n_outliers = outlier_mask.sum()
            if n_outliers > 0:
                print(f"参数 {parameter}, 组 {group}: 发现 {n_outliers} 个异常值")
    
    return clean_data

def create_jmp_quantile_plot(data, parameter, group_col, group_values, cleaned_data=None, fig_size=(3, 3), dpi=100):
    """
    创建JMP风格的Quantile Plot（凹口向下）并返回图像字节流
    如果提供了cleaned_data，则使用清洗后的数据进行绘图
    确保Baseline始终是蓝色，2nd tool是绿色
    """
    # 使用清洗后的数据或原始数据
    plot_data = cleaned_data if cleaned_data is not None else data
    
    fig, ax = plt.subplots(figsize=fig_size, dpi=dpi)
    
    # 确保Baseline和2nd tool始终是固定颜色
    color_map = {
        "Baseline": 'blue',
        "2nd tool": 'green'
    }
    marker_map = {
        "Baseline": 'o',
        "2nd tool": 's'
    }
    
    # 绘制的顺序 - 确保图例显示顺序一致
    ordered_groups = []
    for expected_group in ["Baseline", "2nd tool"]:
        if expected_group in group_values:
            ordered_groups.append(expected_group)
    
    # 如果有其他不在预期内的组，也添加进来
    for group in group_values:
        if group not in ordered_groups:
            ordered_groups.append(group)
    
    for group in ordered_groups:
        # 获取当前组的数据
        group_data = plot_data[plot_data[group_col] == group][parameter].dropna()
        
        if len(group_data) == 0:
            continue
        
        # 排序数据
        sorted_data = np.sort(group_data)
        n = len(sorted_data)
        
        # JMP概率计算公式: (i-0.375)/(n+0.25)
        probabilities = np.array([(i + 1 - 0.375) / (n + 0.25) for i in range(n)])
        
        # 转换为正态分布的分位数
        norm_quantiles = stats.norm.ppf(probabilities)
        
        # 绘制 - 使用对应颜色和标记
        color = color_map.get(group, 'gray')  # 如果不是预期组，使用灰色
        marker = marker_map.get(group, '^')
        
        ax.plot(sorted_data, norm_quantiles, color=color, marker=marker,
                linestyle='-', label=group, markersize=4)
    
    # 添加标题
    ax.set_title(parameter, fontsize=10)
    
    # 添加轴标签
    ax.set_xlabel(parameter, fontsize=8)
    ax.set_ylabel('Normal Quantile', fontsize=8)
    
    # Y轴使用概率刻度
    prob_ticks = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]
    quantile_ticks = stats.norm.ppf(prob_ticks)
    ax.set_yticks(quantile_ticks)
    ax.set_yticklabels([f'{p:.2f}' for p in prob_ticks], fontsize=7)
    ax.tick_params(axis='x', labelsize=7)
    
    # 添加参考线
    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
    
    # 添加图例
    ax.legend(loc='best', fontsize=7)
    
    # 添加网格
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # 转换为字节流
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    plt.close(fig)
    buf.seek(0)
    
    return buf

def create_box_plot(data, parameter, group_col, group_values, cleaned_data=None, fig_size=(3, 3), dpi=100):
    """
    创建Box Plot比较不同工具类别并返回图像字节流
    如果提供了cleaned_data，则使用清洗后的数据进行绘图
    确保Baseline始终在左侧(蓝色)，2nd tool在右侧(绿色)
    """
    # 使用清洗后的数据或原始数据
    plot_data = cleaned_data if cleaned_data is not None else data
    
    fig, ax = plt.subplots(figsize=fig_size, dpi=dpi)
    
    # 确保Baseline总是第一个，2nd tool总是第二个
    ordered_groups = []
    for expected_group in ["Baseline", "2nd tool"]:
        if expected_group in group_values:
            ordered_groups.append(expected_group)
    
    # 如果有其他不在预期内的组，也添加进来
    for group in group_values:
        if group not in ordered_groups:
            ordered_groups.append(group)
    
    # 准备数据
    box_data = []
    valid_labels = []
    
    for group in ordered_groups:
        group_data = plot_data[plot_data[group_col] == group][parameter].dropna()
        if len(group_data) > 0:
            box_data.append(group_data)
            valid_labels.append(group)
    
    if not box_data:
        ax.text(0.5, 0.5, f"无数据可用于 {parameter}", ha='center', va='center', transform=ax.transAxes)
        plt.close(fig)
        return None
    
    # 创建箱线图
    boxplot = ax.boxplot(box_data, patch_artist=True, tick_labels=valid_labels)
    
    # 设置颜色 - 确保Baseline是蓝色(lightblue)，2nd tool是绿色(lightgreen)
    colors = []
    for label in valid_labels:
        if label == "Baseline":
            colors.append('lightblue')
        elif label == "2nd tool":
            colors.append('lightgreen')
        else:
            colors.append('lightgray')  # 默认颜色
            
    for i, patch in enumerate(boxplot['boxes']):
        if i < len(colors):
            patch.set_facecolor(colors[i])
    
    # 添加标题
    ax.set_title(f'Box Plot - {parameter}', fontsize=10)
    ax.set_ylabel(parameter, fontsize=8)
    ax.tick_params(axis='both', labelsize=7)
    
    plt.tight_layout()
    
    # 转换为字节流
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    plt.close(fig)
    buf.seek(0)
    
    return buf

def calculate_statistics(data, parameter, group_col, group_values, cleaned_data=None, jmp_compatible=True):
    """
    计算统计信息：Mean, Std Dev, K-shift
    如果提供了cleaned_data，则使用清洗后的数据计算统计量
    jmp_compatible: 如果为True，使用与JMP兼容的计算方法
    """
    # 使用清洗后的数据或原始数据
    stat_data = cleaned_data if cleaned_data is not None else data
    
    stats_dict = {}
    
    for group in group_values:
        group_data = stat_data[stat_data[group_col] == group][parameter].dropna()
        
        if len(group_data) > 0:
            # 计算均值
            mean_value = np.mean(group_data)
            
            # 计算标准差 - 可以选择兼容JMP的计算方法
            if jmp_compatible:
                # JMP默认使用样本标准差(n-1)
                std_dev = np.std(group_data, ddof=1)
                
                # 对于小样本(n<30)，JMP可能会使用偏差校正
                if len(group_data) < 30:
                    # 这是一个简化的偏差校正因子，可能需要根据实际JMP版本调整
                    correction_factor = np.sqrt((len(group_data) - 1) / len(group_data))
                    std_dev *= correction_factor
            else:
                # 使用标准的样本标准差计算
                std_dev = np.std(group_data, ddof=1)
            
            stats_dict[group] = {
                'Mean': mean_value,
                'Std Dev': std_dev
            }
        else:
            stats_dict[group] = {
                'Mean': np.nan,
                'Std Dev': np.nan
            }
    
    # 计算K-shift (如果有两个或更多组)
    if len(group_values) >= 2:
        baseline_group = group_values[0]  # 假设第一个为baseline
        second_tool_group = group_values[1]  # 假设第二个为2nd tool
        
        if (baseline_group in stats_dict and second_tool_group in stats_dict and
            not np.isnan(stats_dict[baseline_group]['Std Dev']) and
            stats_dict[baseline_group]['Std Dev'] != 0):
            
            stats_dict[second_tool_group]['K-shift'] = (
                stats_dict[second_tool_group]['Mean'] - stats_dict[baseline_group]['Mean']
            ) / stats_dict[baseline_group]['Std Dev']
        else:
            if second_tool_group in stats_dict:
                stats_dict[second_tool_group]['K-shift'] = np.nan
    
    return stats_dict

def create_single_page_ppt(data, parameters, group_col, group_values, cleaned_data=None, output_file='Wafer_Analysis_Report.pptx'):
    """
    创建单页PPT报告，包含所有参数的分析
    如果提供了cleaned_data，则使用清洗后的数据进行绘图和计算
    """
    # 在创建PPT之前，确保组的排序，Baseline应在第一位
    ordered_group_values = []
    
    # 确保Baseline总是第一个，2nd tool总是第二个
    for expected_group in ["Baseline", "2nd tool"]:
        if expected_group in group_values:
            ordered_group_values.append(expected_group)
    
    # 添加其他可能的组
    for group in group_values:
        if group not in ordered_group_values:
            ordered_group_values.append(group)
    
    # 确保至少有一个组
    if not ordered_group_values:
        ordered_group_values = group_values
        
    # 获取正确的基线组和对照组
    baseline_group = ordered_group_values[0]  # 第一个组视为基线
    second_tool_group = ordered_group_values[1] if len(ordered_group_values) > 1 else None
    
    # 创建演示文稿
    prs = Presentation()
    
    # 设置幻灯片大小为标准尺寸(4:3)
    prs.slide_width = Inches(10)
    prs.slide_height = Inches(7.5)
    
    # 添加空白幻灯片
    blank_slide_layout = prs.slide_layouts[6]  # 空白布局
    slide = prs.slides.add_slide(blank_slide_layout)
    
    # 添加标题 - 位置调高
    title_shape = slide.shapes.add_textbox(Inches(0), Inches(0.1), Inches(10), Inches(0.5))
    title_frame = title_shape.text_frame
    title_para = title_frame.add_paragraph()
    title_para.text = "Wafer Measurement Analysis Report"
    title_para.alignment = PP_ALIGN.CENTER
    title_run = title_para.runs[0]
    title_run.font.size = Pt(20)
    title_run.font.bold = True
    
    # 左侧放置Box Plot
    left_panel_x = Inches(0.2)
    left_panel_y = Inches(0.7)  # 位置调高
    left_panel_width = Inches(3.5)
    left_panel_height = Inches(5.0)
    
    # 右侧放置Quantile Plot (2x3网格)
    right_panel_x = Inches(3.8)
    right_panel_y = Inches(0.7)  # 位置调高
    right_panel_width = Inches(6.0)
    right_panel_height = Inches(5.0)
    
    # 计算单个Box Plot的尺寸
    box_plot_height = left_panel_height / len(parameters)
    
    # 计算单个Quantile Plot的尺寸
    quantile_plot_width = right_panel_width / 2
    quantile_plot_height = right_panel_height / 3
    
    # 获取每个参数的统计数据，用于最后的表格
    all_stats = {}
    
    # 创建左侧Box Plot
    for i, parameter in enumerate(parameters):
        # 计算Box Plot位置
        y_pos = left_panel_y + i * box_plot_height
        
        # 创建Box Plot
        box_plot_img = create_box_plot(
            data, 
            parameter, 
            group_col, 
            ordered_group_values, 
            cleaned_data=cleaned_data,
            fig_size=(4, 1.7), 
            dpi=100
        )
        
        if box_plot_img:
            slide.shapes.add_picture(
                box_plot_img, 
                left_panel_x, 
                y_pos, 
                width=left_panel_width
            )
        
        # 计算统计数据，使用兼容JMP的计算方法
        stats_dict = calculate_statistics(data, parameter, group_col, ordered_group_values, 
                                          cleaned_data=cleaned_data, 
                                          jmp_compatible=True)
        all_stats[parameter] = stats_dict
    
    # 创建右侧Quantile Plot (2x3网格)
    grid_positions = [
        # Col 1
        (right_panel_x, right_panel_y),                             # Row 1, Col 1
        (right_panel_x, right_panel_y + quantile_plot_height),      # Row 2, Col 1
        (right_panel_x, right_panel_y + 2 * quantile_plot_height),  # Row 3, Col 1
        # Col 2
        (right_panel_x + quantile_plot_width, right_panel_y),                        # Row 1, Col 2
        (right_panel_x + quantile_plot_width, right_panel_y + quantile_plot_height), # Row 2, Col 2
        (right_panel_x + quantile_plot_width, right_panel_y + 2 * quantile_plot_height) # Row 3, Col 2
    ]
    
    # 最多放置6个Quantile Plot
    for i, parameter in enumerate(parameters[:6]):
        # 计算Quantile Plot位置
        if i < len(grid_positions):
            x_pos, y_pos = grid_positions[i]
            
            # 创建Quantile Plot
            quantile_plot_img = create_jmp_quantile_plot(
                data, 
                parameter, 
                group_col, 
                ordered_group_values,
                cleaned_data=cleaned_data, 
                fig_size=(2.9, 1.7), 
                dpi=100
            )
            
            slide.shapes.add_picture(
                quantile_plot_img, 
                x_pos, 
                y_pos, 
                width=quantile_plot_width
            )
    
    # 创建底部的统计表格 - 调整位置和大小
    table_rows = len(parameters) + 2  # 参数数量 + 标题两行
    table_cols = 5  # Condition, BSL Mean, BSL Std Dev, 2nd Tool Mean, K-shift
    
    table = slide.shapes.add_table(
        table_rows, 
        table_cols,
        Inches(0.5), 
        Inches(5.8),  # 位置略向上调整
        Inches(9), 
        Inches(1.5)
    ).table
    
    # 设置列宽
    table.columns[0].width = Inches(2.0)
    for i in range(1, 5):
        table.columns[i].width = Inches(1.75)
    
    # 添加表头 - 完全符合JMP风格
    baseline_group = group_values[0] if "Baseline" in group_values else group_values[0]
    second_tool_group = group_values[1] if "2nd tool" in group_values else (group_values[1] if len(group_values) > 1 else None)
    
    header_cells = [
        "Condition", baseline_group, "", second_tool_group, ""
    ]
    for i, text in enumerate(header_cells):
        cell = table.cell(0, i)
        cell.text = text if text is not None else ""
        # 安全地设置粗体和字体大小
        para = cell.text_frame.paragraphs[0]
        para.alignment = PP_ALIGN.CENTER
        if not para.runs:
            run = para.add_run()
            run.text = text if text is not None else ""
        else:
            run = para.runs[0]
        run.font.bold = True
        run.font.size = Pt(11)
    
    # 第二行表头
    subheader_cells = [
        "Statistics", "Mean", "Std Dev", "Mean", "K-shift"
    ]
    for i, text in enumerate(subheader_cells):
        cell = table.cell(1, i)
        cell.text = text
        # 安全地设置粗体和字体大小
        para = cell.text_frame.paragraphs[0]
        para.alignment = PP_ALIGN.CENTER
        if not para.runs:
            run = para.add_run()
            run.text = text
        else:
            run = para.runs[0]
        run.font.bold = True
        run.font.size = Pt(11)
    
    # 添加数据行
    for i, parameter in enumerate(parameters):
        stats_dict = all_stats.get(parameter, {})
        
        if not stats_dict:
            continue
            
        # 确保统计计算是对正确的组
        baseline_group = baseline_group if baseline_group in stats_dict else list(stats_dict.keys())[0]
        second_tool_group = second_tool_group if second_tool_group in stats_dict else (list(stats_dict.keys())[1] if len(stats_dict) > 1 else None)
        
        # 准备数据
        baseline_stats = stats_dict.get(baseline_group, {})
        second_tool_stats = stats_dict.get(second_tool_group, {}) if second_tool_group else {}
        
        # 为小值启用科学记号
        def format_value(value, param_name):
            if value is None or np.isnan(value):
                return 'N/A'
            
            # 判断是否为非常小的值 (例如LK类似的量级)
            if 'LK' in param_name and abs(value) < 0.001:
                return f"{value:.4e}"  # 使用科学记号
            elif abs(value) < 0.0001:  # 其他很小的值也使用科学记号
                return f"{value:.4e}"
            else:
                return f"{value:.4f}"  # 常规数值使用固定小数点
        
        row_data = [
            parameter,
            format_value(baseline_stats.get('Mean', np.nan), parameter) if 'Mean' in baseline_stats else 'N/A',
            format_value(baseline_stats.get('Std Dev', np.nan), parameter) if 'Std Dev' in baseline_stats else 'N/A',
            format_value(second_tool_stats.get('Mean', np.nan), parameter) if 'Mean' in second_tool_stats else 'N/A',
            format_value(second_tool_stats.get('K-shift', np.nan), parameter) if 'K-shift' in second_tool_stats else 'N/A'
        ]
        
        # 填充表格
        for j, text in enumerate(row_data):
            cell = table.cell(i + 2, j)
            cell.text = text
            para = cell.text_frame.paragraphs[0]
            para.alignment = PP_ALIGN.CENTER
            if not para.runs:
                run = para.add_run()
                run.text = text
            else:
                run = para.runs[0]
            run.font.size = Pt(10)
    
    # 保存演示文稿
    prs.save(output_file)
    print(f"已创建PPT文件: {output_file}")
    
    return output_file

def export_to_excel(data, wafer_id_col, condition_col, output_file='Wafer_Measurement_Data.xlsx'):
    """
    将处理后的数据导出到Excel
    """
    try:
        # 创建一个ExcelWriter对象
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # 导出主数据表
            data.to_excel(writer, sheet_name='Transformed_Data', index=False)
            
            # 创建分组数据的表
            conditions = data[condition_col].unique()
            for condition in conditions:
                condition_data = data[data[condition_col] == condition]
                # 获取不包含wafer_id和condition列的纯测量数据
                measure_data = condition_data.drop(columns=[wafer_id_col, condition_col])
                
                # 创建描述性统计信息表
                stats_df = measure_data.describe().T
                
                # 将条件特定数据和统计信息导出到单独的表
                sheet_name = f"{condition}_Data"[:31]  # Excel表名最长为31个字符
                condition_data.to_excel(writer, sheet_name=sheet_name, index=False)
                
                # 统计信息表
                stats_sheet_name = f"{condition}_Stats"[:31]
                stats_df.to_excel(writer, sheet_name=stats_sheet_name)
        
        print(f"数据已导出到Excel: {output_file}")
        return True
    except Exception as e:
        print(f"导出Excel时出错: {e}")
        return False

def create_sample_data(n_wafers=30):
    """
    创建模拟数据集，包含Wafer ID和WaferID的差异，
    以及Condition列替代BSL和2nd tool
    """
    # 创建wafer IDs
    wafer_ids = [f'Wafer_{i:03d}' for i in range(1, n_wafers+1)]
    
    # 条件类型
    condition_types = ['Baseline', '2nd tool']
    
    # 创建condition_list数据
    condition_data = pd.DataFrame({
        'WaferID': wafer_ids,
        'Condition': np.random.choice(condition_types, size=n_wafers)
    })
    
    # 创建量测数据
    param_names = ['Con_M3LA', 'Con_M3LB', 'Rc_V2v', 'LK_M3LA', 'LK_M3LB']
    
    rows = []
    for wafer_id in wafer_ids:
        for param in param_names:
            # 为每个wafer和每个参数创建多个site测量
            n_sites = np.random.randint(1, 5)
            for site in range(1, n_sites+1):
                # 随机生成0-9之间的值，添加少量异常值
                value = np.random.uniform(0, 9)
                
                # 5%的概率生成异常值
                if np.random.random() < 0.05:
                    value = value * (3 + np.random.random() * 2)  # 3-5倍的异常值
                
                rows.append({
                    'Wafer ID': wafer_id,
                    'Parameter Name': param,
                    'Site': f'Site_{site}',
                    'Site Value': value
                })
    
    query_data = pd.DataFrame(rows)
    
    return query_data, condition_data

def main():
    """
    主函数：执行整个数据处理和分析流程
    """
    # 检查是否能读取实际数据
    try:
        query_data, condition_data = read_data('IEDA2_query.xlsx', 'condition_list.xlsx')
        if query_data is None or condition_data is None:
            raise Exception("无法读取实际数据文件")
        
        # 转换数据
        transformed_data, condition_types, measure_parameters, wafer_id_col, condition_col = transform_data(query_data, condition_data)
        
    except Exception as e:
        print(f"使用实际数据时出错: {e}")
        print("将创建模拟数据继续演示...")
        
        # 创建模拟数据
        query_data, condition_data = create_sample_data(30)
        
        # 转换模拟数据
        transformed_data, condition_types, measure_parameters, wafer_id_col, condition_col = transform_data(query_data, condition_data)
    
    # 查找条件列
    if not condition_col:
        # 查找可能的条件列（除了Wafer ID之外的第一列）
        for col in transformed_data.columns:
            if "wafer" not in col.lower():
                condition_col = col
                break
    
    # 使用从query_data中提取的电性量测项目作为参数列表
    # 注意：这些参数必须在transformed_data中存在
    available_parameters = []
    for param in measure_parameters:
        if param in transformed_data.columns:
            available_parameters.append(param)
    
    if len(available_parameters) == 0:
        # 如果没有找到可用参数，则尝试使用transformed_data中的所有非ID、非条件列
        for col in transformed_data.columns:
            if "wafer" not in col.lower() and col != condition_col:
                available_parameters.append(col)
    
    print(f"\n使用条件列: {condition_col}")
    print(f"发现的参数: {available_parameters}")
    
    # 确保有条件列和至少一个参数
    if not condition_col or not available_parameters:
        print("无法找到必要的列，请检查数据格式")
        return
    
    # 1. 导出原始转换后的数据到Excel
    excel_output = 'Wafer_Measurement_Data.xlsx'
    export_to_excel(transformed_data, wafer_id_col, condition_col, excel_output)
    
    # 2. 移除各参数的异常值（创建数据副本以不影响原始数据）
    cleaned_data = transformed_data.copy()
    print("\n检测并移除异常值进行分析:")
    for param in available_parameters:
        param_cleaned = remove_outliers(
            transformed_data, 
            param, 
            condition_col, 
            condition_types, 
            method='iqr', 
            k=1.5
        )
        # 只更新当前参数列，保持其他列不变
        cleaned_data[param] = param_cleaned[param]
    
    # 3. 创建PPT报告，使用清洗后的数据
    output_file = 'Wafer_Measurement_Analysis.pptx'
    create_single_page_ppt(
        transformed_data, 
        available_parameters, 
        condition_col, 
        condition_types, 
        cleaned_data=cleaned_data,
        output_file=output_file
    )
    
    print("\n分析总结:")
    print("1. JMP风格Quantile Plot凹口向下是由于使用(i-0.375)/(n+0.25)概率公式")
    print("2. Python标准库默认使用i/(n+1)公式，产生凹口向上的曲线")
    print("3. 通过修改概率计算方法，成功模拟JMP风格的Quantile Plot")
    print("4. 自动检测并移除异常值用于分析，但原始数据保持不变")
    print(f"5. 原始数据已导出至Excel文件: {excel_output}")
    print(f"6. 分析结果已保存至PowerPoint文件: {output_file}")

if __name__ == "__main__":
    main()
